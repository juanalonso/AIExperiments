{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "DALL-E dVAE",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuIthHhJr67R"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiPglRiW8rPc"
      },
      "source": [
        "!pip install git+https://github.com/openai/DALL-E.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ElObNI8qIs"
      },
      "source": [
        "import io\n",
        "import os, sys\n",
        "import requests\n",
        "import PIL\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from dall_e          import map_pixels, unmap_pixels, load_model\n",
        "from IPython.display import display, display_markdown\n",
        "\n",
        "target_image_size = 256\n",
        "\n",
        "#torch.cuda.current_device()\n",
        "#torch.cuda.get_device_name(0)\n",
        "#torch.cuda.is_available()\n",
        "\n",
        "def download_image(url):\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    return PIL.Image.open(io.BytesIO(resp.content))\n",
        "\n",
        "def preprocess(img):\n",
        "    s = min(img.size)\n",
        "    \n",
        "    if s < target_image_size:\n",
        "        raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
        "        \n",
        "    r = target_image_size / s\n",
        "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
        "    img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
        "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
        "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
        "    return map_pixels(img)\n",
        "\n",
        "def decode(z, savefile=None):\n",
        "  z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
        "\n",
        "  x_stats = dec(z).float()\n",
        "  x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
        "  x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
        "\n",
        "  display(x_rec)\n",
        "\n",
        "  if (savefile is not None):\n",
        "    x_rec.save(savefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nZZ9NNZ8qIz"
      },
      "source": [
        "# This can be changed to a GPU, e.g. 'cuda:0'.\n",
        "dev = torch.device('cpu')\n",
        "\n",
        "# For faster load times, download these files locally and use the local paths instead.\n",
        "enc = load_model(\"https://cdn.openai.com/dall-e/encoder.pkl\", dev)\n",
        "dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmGBWdma8qI1"
      },
      "source": [
        "x = preprocess(download_image('https://c.pxhere.com/photos/7a/ad/dog_labrador_light_brown_hundeportrait_out_dog_head_nature_pet-655500.jpg!d'))\n",
        "display(T.ToPILImage(mode='RGB')(x[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojB5syRe8qI1"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "z_logits = enc(x)\n",
        "z = torch.argmax(z_logits, axis=1)\n",
        "\n",
        "decode(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwAzDwarmIBR"
      },
      "source": [
        "z_rand = torch.rand(1,32,32)*1024\n",
        "z_rand = z_rand.long()\n",
        "\n",
        "decode(z_rand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYkbGH9KXCU0"
      },
      "source": [
        "z = torch.argmax(z_logits, axis=1)\n",
        "\n",
        "v =  random.randrange(8192)\n",
        "index = torch.tensor([0,1,2,3,4,5,26,27,28,29,30,31])\n",
        "\n",
        "z[0].index_fill_(0, index, v)\n",
        "z[0].index_fill_(1, index, v)\n",
        "decode(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0DZX_a0RClo"
      },
      "source": [
        "mask = torch.ones(1,32,32)\n",
        "index = torch.tensor([0,1,2,3,4,5,26,27,28,29,30,31])\n",
        "mask[0].index_fill_(0, index, 0)\n",
        "mask[0].index_fill_(1, index, 0)\n",
        "\n",
        "z_rand = torch.rand(1,32,32)*8192*(1-mask)\n",
        "z_image = torch.argmax(z_logits, axis=1)*mask\n",
        "\n",
        "z_comp = z_rand + z_image\n",
        "z_comp = z_comp.long()\n",
        "decode(z_comp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGd4NAJjWR53"
      },
      "source": [
        "mask = torch.zeros(1,32,32)\n",
        "rand = torch.rand(1,32,32)*8192\n",
        "base = torch.argmax(z_logits, axis=1)\n",
        "\n",
        "for f in range(30):\n",
        "  mask[0].index_fill_(0, torch.tensor([f,30,31]), 1)\n",
        "  #mask[0].index_fill_(0, torch.tensor(f), 1)\n",
        "  z_comp = rand*(1-mask) + base*mask\n",
        "  decode(z_comp.long(), savefile=\"drive/MyDrive/AIExperiments/DALLE/anim_3_%02d.jpg\" % f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}